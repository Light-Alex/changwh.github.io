---
layout: post
title:  "CRNN论文的阅读与学习"
date:   2019-07-29 00:00:00 +0800
categories: cv
tags: CRNN
author: ac酱
mathjax: true
---

* content
{:toc}
最近在项目中使用了CTPN及CRNN进行中文OCR系统的构造，因此很有必要对这两个网络进行更进一步的了解与学习。本文将记录与CRNN相关的内容。



## CRNN流程概括

<center>
<img src="https://raw.githubusercontent.com/changwh/changwh.github.io/master/_posts/res/2019-07-29-crnn-paper-reading/architecture.jpg" />
<div>CRNN网络结构</div>
</center>

<center>
<img src="https://raw.githubusercontent.com/changwh/changwh.github.io/master/_posts/res/2019-07-29-crnn-paper-reading/config_summary.jpg" />
<div>CRNN具体结构</div>
</center>

CRNN的网络结构由三部分组成，分别是卷积层，循环层和转录层。

在CRNN的底部，卷积层自动从每个输入图像中提取特征序列。在卷积网络之上，构建了一个循环网络，用于对卷积层输出的特征序列的每一帧进行预测。采用CRNN顶部的转录层将循环层的每帧预测转化为标签序列。虽然CRNN由不同类型的网络架构（如CNN和RNN）组成，但可以通过一个损失函数进行联合训练。

### 卷积层

采用标准CNN模型（去除全连接层）中的卷积层和最大池化层来构造，用于从输入图像中提取序列特征表示。在进入网络之前，所有的图像需要缩放到相同的高度。然后从卷积层组件产生的特征图中提取特征向量序列作为循环层的输入。特征序列的每一个特征向量在特征图上按列从左到右生成。这意味着第i个特征向量是所有特征图第i列的连接。每列的宽度固定为单个像素。

特征图的每列对应于原始图像的一个矩形区域（称为感受野），并且这些矩形区域与特征图上从左到右的相应列具有相同的顺序。特征序列中的每个向量关联一个感受野，并且可以被认为是该区域的图像描述符。

由于CNN要求将输入图像缩放到固定尺寸，以满足其固定的输入尺寸。而类序列对象的长度变化很大，因此CNN不适合类序列对象。在CRNN中，我们将深度特征传递到序列表示中，以便对类序列对象的长度变化保持适用性的不变。

### 循环层
以深度双向循环神经网络作为循环层，对特征序列$x=x_1,...,x_T$中的每一帧$x_t$都进行预测得到标签分布$y_t$。

这样的循环层具有三个优点：

* 首先，RNN具有很强的捕获序列内上下文信息的能力。对于基于图像的序列识别使用上下文提示比独立处理每个符号更稳定且更有帮助。以场景文本识别为例，宽字符可能需要一些连续的帧来完全描述。此外，一些模糊的字符在观察其上下文时更容易区分，例如，通过对比字符高度更容易识别“il”而不是分别识别它们中的每一个。
* 其次，RNN可以将误差差值反向传播到其输入，即卷积层，从而允许我们在统一的网络中共同训练循环层和卷积层。
* 第三，RNN能够从头到尾对任意长度的序列进行操作。

LSTM是定向的，它只使用过去的上下文。而在基于图像的序列中，两个方向的上下文是相互有用且互补的。因此，我们将两个LSTM，一个向前和一个向后组合到一个双向LSTM中。此外，可以堆叠多个双向LSTM，得到深双向LSTM。深层结构允许比浅层抽象更高层次的抽象，并且在语音识别任务中取得了显著的性能改进。

在循环层中，误差使用BPTT进行反向传播。在循环层的底部，传播差异的序列被连接成图，即将特征图转换为特征序列的操作进行反转，并反馈到卷积层。实际上，我们创建一个称为“Map-to-Sequence”的自定义网络层，作为卷积层和循环层之间的桥梁。

### 转录层

转录是将RNN所做的每帧预测转换成标签序列的过程。数学上，转录是根据每帧预测找到具有最高概率的标签序列。
在实践中，存在两种转录模式，即无词典转录和基于词典的转录。词典是一组标签序列，预测将受词典的约束，例如拼写检查词典。在无词典模式中，预测时没有任何词典。在基于词典的模式中，通过选择具有最高概率的标签序列进行预测。

#### 标签序列的概率

采用CTC层定义的条件概率，这个概率是为每帧预测为$y=y_1,...,y_T$的条件下的标签序列$l$定义的，并且它忽略了每个$l$中的标签的位置。因此，当我们使用这种概率的副对数似然作为训练网络的目标函数时，我们只需要图片和相应的标签序列，避免了标注单个字符位置的劳动。

条件概率的公式如下：输入是序列$y=y_1,...y_T$，$T$表示序列的长度。每个$y_t \in \Re^{\| \cal L’\|}$（$\Re$原意为虚数的实部，这里表示$y_t$存在于长度为$\cal L’$的标签列表中）是一个在集合$\cal L’= \cal L \cup $'-'(怀疑原文遗漏了'-')的概率分布，其中$\cal L$包含了任务中的所有标签（例如所有英文字母），以及由'-'表示的空白。序列到序列的映射函数$B$定义在序列$\pi \in \cal L'^T$上，$T$是（序列$\pi$的）长度。$B$将$\pi$映射到$l$上，首先去除重复的标签，之后去除空白。例如$B$将“--hh-e-l-ll-oo--”映射到“hello”。然后条件概率被定义为被$B$映射为$l$的所有$\pi$的概率之和。

\begin{equation} p(l\|y)=\sum_{\pi :\cal B(\pi )=l} p(\pi \|y), \tag{1} \end{equation}

$\pi$的概率被定义为$p(\pi \| y)=\prod_{t=1}^{T}y_{\pi_{t}}^{t}$，$y_{\pi_{t}}^{t}$是在时刻$t$时有标签$\pi_t$的概率。由于存在指数级数量的求和项，直接计算(1)是不可行的。使用前向算法（CTC论文中提出的）可以有效计算(1)。

#### 无词典转录

在这种模式下，将具有(1)中定义的最高的概率的序列$l^\*$作为预测。由于不存在精确求解的可行性算法，我们使用CTC论文中的策略。序列$l^\*$是通过$l^\*\approx {\cal B}(\arg\max_{\pi}p(\pi\|y))$近似发现的，即在每个时刻$t$取概率最高的标签$\pi_t$，将结果序列映射为$l^\*$

#### 基于词典的转录

在这种模式下，每个测试样本都将和词典$\cal D$相关联。基本上，通过选择词典中的拥有(1)中定义的最高条件概率的序列，来识别标签序列，即$l^\*=\arg\max_{l\in {\cal D}}p(l\|y)$。然而对于例如包含5万词的Hunspell拼写检查词典的大型词典，进行详尽的搜索，即对词典中的所有序列计算(1)并选择最高概率的一个是非常耗时的。为了解决这个问题，我们观察到，无词典转录的标签序列预测在编辑距离度量下通常是接近真实数据的。这表示我们可以将搜索限制在最相邻的候选目标${\cal N}_\delta(l’)$中,其中$\delta$是最大编辑距离，$l'$是无词典转录模式下由$y$转录得到的序列。

\begin{equation} l^\*=\arg\max_{l\in{\cal N}_{\delta}(l’)}p(l\|y), \tag{2} \end{equation}

候选目标${\cal N}_\delta(l’)$能通过BK树数据结构有效的找到，这是一种专门适用于离散度量空间的度量树。BK树的搜索时间复杂度为$O(\log\|{\cal D}\|)$，其中$\|{\cal D}\|$是词典大小。因此这个方案很容易扩展到非常大的词典。在我们的方法中，为一个词典离线构造一个BK树。然后使用树执行快速在线搜索，通过查找具有与查询序列的编辑距离小于等于$\delta$的序列。

## 训练

## 特性

* 与大多数现有的组件需要单独训练和协调的算法相比，它是端对端训练的。
* 它自然地处理任意长度的序列，不涉及字符分割或水平尺度归一化。
* 它不仅限于任何预定义的词汇，并且在无词典和基于词典的场景文本识别任务中都取得了显著的表现。
* 它产生了一个有效而小得多的模型，这对于现实世界的应用场景更为实用。

## 独特的优点

* 可以直接从序列标签（例如单词）学习，不需要详细的标注（例如字符）；
* 直接从图像数据学习信息表示时，既不需要手工特征也不需要预处理步骤，包括二值化/分割，组件定位等；
* 具有与RNN相同的性质，能够产生一系列标签；
* 对类序列对象的长度无约束，只需要在训练阶段和测试阶段对高度进行归一化；
* 它比标准DCNN模型包含的参数要少得多，占用更少的存储空间（不是基于字符组合识别，而是单字符识别，所以分类的数量较少）。

## 关键的IDEA


## 文中提及的相关工作
CTC
BK-tree

**to be continued**
